{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Gathers data from all videos in 'training videos' and displays the data on screen in real time, converts to angles using functions.py, saves the videos to 'training data'. Also visualizes landmark x,y,z coordinates over time and joints over time",
   "id": "8302dc57f49286ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 1,
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "from contourpy import as_z_interp\n",
    "import matplotlib.pyplot as plt\n",
    "import functions\n",
    "#import importlib\n",
    "#importlib.reload(functions)\n",
    "import os\n",
    "from collections import deque\n",
    "\n",
    "from pathlib import Path\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n"
   ],
   "id": "initial_id"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T20:20:58.897548Z",
     "start_time": "2025-07-03T20:20:58.889727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "window_length = 10\n",
    "allAngles = []\n",
    "allPoints = []\n",
    "\n",
    "#Set up different Joints. The value at index 1 is the middle of the joint\n",
    "JOINTS_TO_TRACK = {\n",
    "    \"left_elbow\": [mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.LEFT_ELBOW, mp_pose.PoseLandmark.LEFT_WRIST],\n",
    "    \"right_elbow\": [mp_pose.PoseLandmark.RIGHT_SHOULDER, mp_pose.PoseLandmark.RIGHT_ELBOW, mp_pose.PoseLandmark.RIGHT_WRIST],\n",
    "    \"left_knee\": [mp_pose.PoseLandmark.LEFT_HIP, mp_pose.PoseLandmark.LEFT_KNEE, mp_pose.PoseLandmark.LEFT_ANKLE],\n",
    "    \"right_knee\": [mp_pose.PoseLandmark.RIGHT_HIP, mp_pose.PoseLandmark.RIGHT_KNEE, mp_pose.PoseLandmark.RIGHT_ANKLE],\n",
    "    \"right_hip\": [mp_pose.PoseLandmark.RIGHT_KNEE, mp_pose.PoseLandmark.RIGHT_HIP, mp_pose.PoseLandmark.RIGHT_SHOULDER],\n",
    "    \"left_hip\": [mp_pose.PoseLandmark.LEFT_KNEE, mp_pose.PoseLandmark.LEFT_HIP, mp_pose.PoseLandmark.LEFT_SHOULDER],\n",
    "    \"left_shoulder\": [mp_pose.PoseLandmark.LEFT_HIP, mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.LEFT_ELBOW],\n",
    "    \"right_shoulder\": [mp_pose.PoseLandmark.RIGHT_HIP, mp_pose.PoseLandmark.RIGHT_SHOULDER, mp_pose.PoseLandmark.RIGHT_ELBOW],\n",
    "}\n",
    "\n",
    "landmark_indeces_to_labels = {\n",
    "    0: \"nose\",\n",
    "    1: \"left eye inner\",\n",
    "    2: \"left eye\",\n",
    "    3: \"left eye outer\",\n",
    "    4: \"right eye inner\",\n",
    "    5: \"right eye\",\n",
    "    6: \"right eye outer\",\n",
    "    7: \"left ear\",\n",
    "    8: \"right ear\",\n",
    "    9: \"mouth left\",\n",
    "    10: \"mouth right\",\n",
    "    11: \"left shoulder\",\n",
    "    12: \"right shoulder\",\n",
    "    13: \"left elbow\",\n",
    "    14: \"right elbow\",\n",
    "    15: \"left wrist\",\n",
    "    16: \"right wrist\",\n",
    "    17: \"left pinky\",\n",
    "    18: \"right pinky\",\n",
    "    19: \"left index\",\n",
    "    20: \"right index\",\n",
    "    21: \"left thumb\",\n",
    "    22: \"right thumb\",\n",
    "    23: \"left hip\",\n",
    "    24: \"right hip\",\n",
    "    25: \"left knee\",\n",
    "    26: \"right knee\",\n",
    "    27: \"left ankle\",\n",
    "    28: \"right ankle\",\n",
    "    29: \"left heel\",\n",
    "    30: \"right heel\",\n",
    "    31: \"left foot index\",\n",
    "    32: \"right foot index\"\n",
    "}\n",
    "\n",
    "#initializes a map to store the x,y,z coordinate of each body part at each frame\n",
    "landmark_positions = {}\n",
    "for position in mp_pose.PoseLandmark:\n",
    "    landmark_positions[position.value] = [[],[],[]]\n",
    "\n",
    "#Stores the angles calculated at each frame in a different map\n",
    "angle_history = {joint: [] for joint in JOINTS_TO_TRACK}\n",
    "\n",
    "# Get current script, and find the training videos script relative to it\n",
    "script_dir = os.path.dirname(os.path.abspath(\"main.ipynb\"))\n",
    "videos_dir = os.path.abspath(os.path.join(script_dir, '..', 'training videos'))\n",
    "\n",
    "# Normalize path just for fun\n",
    "videos_dir = os.path.normpath(videos_dir)"
   ],
   "id": "d0c75edea7a9d16",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T20:22:22.444757Z",
     "start_time": "2025-07-03T20:21:05.659078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cap = cv2.VideoCapture()\n",
    "\n",
    "\n",
    "for filename in os.listdir(videos_dir):\n",
    "    if filename.endswith(('.mp4', '.avi', '.mov', 'mkv')):  # filter video files\n",
    "\n",
    "        video_path = os.path.join(videos_dir, filename)\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "        #UNCOMMENT TO RECORD MEDIAPIPE FOOTAGE\n",
    "        '''fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(f'{filename} annotated_output.mp4', fourcc, fps, (width, height))'''\n",
    "\n",
    "        if not cap.isOpened():\n",
    "            continue\n",
    "\n",
    "        with mp_pose.Pose(min_detection_confidence=0.85, min_tracking_confidence=0.85) as pose:\n",
    "\n",
    "            #Store Angle History\n",
    "            angle_windows = {}\n",
    "\n",
    "            for joint_name in JOINTS_TO_TRACK.keys():\n",
    "                # INIT DEQUES TO TAKE THE AVERAGE OF DATA IN A \"SLIDING WINDOW\"\n",
    "                # THIS HELPS TO SMOOTH THE DATA. Adjust Window Length to set smoothness\n",
    "                # of data\n",
    "                angle_windows[joint_name] = deque([], maxlen=window_length)\n",
    "\n",
    "            while cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "\n",
    "                #Detect if video loop is over and update data\n",
    "                if not ret:\n",
    "                    points = {f\"landmark_{k}\": np.array(v) for k, v in landmark_positions.items()}\n",
    "                    angles = {k: np.array(v) for k, v in angle_history.items()}\n",
    "                    if filename.startswith(\"squat\"):\n",
    "                        functions.save_lift_data(\"squat\", points, angles, filename_tag=filename)\n",
    "                    elif filename.startswith(\"bench\"):\n",
    "                        functions.save_lift_data(\"bench\", points, angles, filename_tag=filename)\n",
    "                    elif filename.startswith(\"deadlift\"):\n",
    "                        functions.save_lift_data(\"deadlift\", points, angles, filename_tag=filename)\n",
    "                    break\n",
    "\n",
    "                #Recolor the frame to RGB\n",
    "                image = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "                image.flags.writeable = False\n",
    "\n",
    "                results = pose.process(image)\n",
    "\n",
    "                #Recolor the frame back to BGR\n",
    "                image.flags.writeable = True\n",
    "                image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "\n",
    "\n",
    "\n",
    "                try:\n",
    "                    #EXTRACT LANDMARKS AND APPEND X,Y,Z COORDS TO LANDMARK_POSITIONS\n",
    "                    landmarks = results.pose_landmarks.landmark\n",
    "                    for position in mp_pose.PoseLandmark:\n",
    "                        landmark = landmarks[position.value]\n",
    "                        landmark_positions[position.value][0].append(round(landmark.x,2))\n",
    "                        landmark_positions[position.value][1].append(round(landmark.y,2))\n",
    "                        landmark_positions[position.value][2].append(round(landmark.z,2))\n",
    "\n",
    "\n",
    "                    # GO THRU EACH JOINT GIVEN IN JOINTS_TO_TRACK\n",
    "                    # landmark_indeces represent the landmarks we passed to JOINTS_TO_TRACK\n",
    "\n",
    "                    # for example, if joint_name = left elbow, then the landmark indeces are\n",
    "                    # the left wrist, elbow, and shoulder, and you can access the x,y,z coordinates\n",
    "                    # of each of these by index\n",
    "                    for joint_name, landmark_indices in JOINTS_TO_TRACK.items():\n",
    "\n",
    "                        try: #EXECUTE IF JOINT HAS ACTIVE DATA\n",
    "\n",
    "                            a = landmarks[landmark_indices[0].value]\n",
    "                            b = landmarks[landmark_indices[1].value]\n",
    "                            c = landmarks[landmark_indices[2].value]\n",
    "\n",
    "                            # Use only x, y for 2D analysis\n",
    "                            angle = functions.calculate_angle(\n",
    "                                [a.x, a.y, a.z],\n",
    "                                [b.x, b.y, b.z],\n",
    "                                [c.x, c.y, c.z]\n",
    "                            )\n",
    "\n",
    "                        # ADD CURRENT ANGLE AT FRAME TO ANGLE_WINDOWS. IF ANGLE_WINDOWS IS AS LONG AS THE DEQUE EARLIER,\n",
    "                        # TAKE THE MEAN OF THE DEQUE. DEQUE IS UPDATED AT EACH FRAME, WITH THE FIRST VALUE IN THE DEQUE\n",
    "                        # BEING REMOVED AS THE LAST IS ADDED (FIFO DATA STRUCTURE)\n",
    "                            angle_windows[joint_name].append(angle)\n",
    "                            if len(angle_windows[joint_name]) == window_length:\n",
    "                                rolling_avg = np.mean(angle_windows[joint_name])\n",
    "                                angle_history[joint_name].append(int(rolling_avg))\n",
    "\n",
    "                            #ADD COORDINATES TO VIDEO\n",
    "                            x = a.x * cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "                            y = a.y * cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "                            cv2.putText(image, f\"{str(round(x ,2))}  {str(round(y,2))} {str(round(a.z,2))}\",\n",
    "                                np.multiply([a.x, a.y-.02], [cap.get(cv2.CAP_PROP_FRAME_WIDTH),cap.get(cv2.CAP_PROP_FRAME_HEIGHT)]).astype(int), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                0.5, (100,200,200), 2, cv2.LINE_AA)\n",
    "\n",
    "                        #IF LANDMARK IS NOT FOUND IN FOOTAGE, SET ANGLE TO NOT A NUMBER\n",
    "                        except Exception:\n",
    "                            angle = np.nan\n",
    "\n",
    "                        #IF WE HAVE AN ACTIVE ANGLE, DISPLAY THE ANGLE ON SCREEN\n",
    "                        '''if not np.isnan(angle):\n",
    "                            b_coords = np.multiply([b.x, b.y], [image.shape[1], image.shape[0]]).astype(int)\n",
    "                            cv2.putText(\n",
    "                                image,\n",
    "                                f\"{joint_name}: {int(angle)}\",\n",
    "                                tuple(b_coords),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                0.5,\n",
    "                                (255,255,255),\n",
    "                                2,\n",
    "                                cv2.LINE_AA\n",
    "                            )'''\n",
    "                #IF WE CANNOT EXTRACT LANDMARKS, JUST PASS\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                #DRAW LANDMARKS AND CONNECTIONS IN VIDEO\n",
    "                mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                          mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2),\n",
    "                                          mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                          )\n",
    "                cv2.imshow('Mediapipe Feed',image)\n",
    "\n",
    "                # UNCOMMENT TO RECORD MEDIAPIPE FOOTAGE\n",
    "                #out.write(image)\n",
    "\n",
    "\n",
    "                #IF USER PRESSES Q, EXIT\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    print(\"User requested exit.\")\n",
    "                    break\n",
    "\n",
    "            #UNCOMMENT TO RECORD MEDIAPIPE FOOTAGE\n",
    "            #out.release()\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ],
   "id": "a320e38893aa6053",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User requested exit.\n",
      "User requested exit.\n",
      "User requested exit.\n",
      "User requested exit.\n",
      "User requested exit.\n",
      "User requested exit.\n",
      "User requested exit.\n",
      "User requested exit.\n",
      "User requested exit.\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#NPZ VIEWING\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#CHANGE FILES TO VIEW DIFFERENT LIFTS\n",
    "data_dir = os.path.join(script_dir, '..', 'training data')\n",
    "data = np.load(f\"{data_dir}\\\\deadlift files\\\\deadlift lift data.npz\")\n",
    "\n",
    "\n",
    "#print(data)\n",
    "# for key in data:\n",
    "#     joint_data = data[key]\n",
    "#     print(f\"{key}: shape = {joint_data.shape}\")\n",
    "#     plt.plot(joint_data, label=key)\n",
    "#     plt.title(f\"{key} over time\")\n",
    "#     plt.xlabel(\"Frame\")\n",
    "#     plt.xlim(0,joint_data.shape[0])\n",
    "#     plt.ylim(0,180)\n",
    "#     plt.ylabel(\"Angle\")\n",
    "#\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "i = 0\n",
    "\n",
    "for key in data:\n",
    "    if \"landmark\" in key:\n",
    "        for coordinate in data[key]:\n",
    "            # ISOLATE THE INDEX WHERE LANDMARK NAME IS FOUND SO WE CNA ISOLATE LANDMARK NAME\n",
    "            # indexing is getting a little convoluted. Just know that this isolates the\n",
    "            # landmark index and maps it to the landmark name\n",
    "            s = key.find(\"landmark_\")\n",
    "            current_landmark_index = int(key[s+9:])\n",
    "            current_landmark_name = landmark_indeces_to_labels[current_landmark_index]\n",
    "\n",
    "            plt.plot(coordinate, label=chr(120+i))\n",
    "            i += 1\n",
    "            if i == 3:\n",
    "                i = 0\n",
    "\n",
    "        plt.title(f\"{key[:s - 9]}{current_landmark_name} coordinates over time\")\n",
    "        plt.xlabel(\"Frame\")\n",
    "        plt.ylabel('Coordinate Position on Screen')\n",
    "        plt.ylim(-1,1)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    else:\n",
    "        joint_data = data[key]\n",
    "        print(f\"{key}: shape = {joint_data.shape}\")\n",
    "        plt.plot(joint_data, label=key)\n",
    "        plt.title(f\"{key} over time\")\n",
    "        plt.xlabel(\"Frame\")\n",
    "        plt.xlim(0,joint_data.shape[0])\n",
    "        plt.ylim(0,180)\n",
    "        plt.ylabel(\"Angle\")\n",
    "\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ],
   "id": "56fe24f5b544cfaa",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
